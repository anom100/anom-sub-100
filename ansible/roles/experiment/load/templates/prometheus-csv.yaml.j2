apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-csv-configmap
  namespace: {{ prometheus_csv_namespace }}
data:
  metrics.txt: |
    cilium_forwarded_packets @@@ sum(rate(cilium_forward_count_total{k8s_app="cilium", pod=~"cilium.*"}[1m]))
    cilium_forwarded_traffic @@@ sum(rate(cilium_forward_bytes_total{k8s_app="cilium", pod=~"cilium.*"}[1m])) * 8
    cilium_open_fds @@@ sum(cilium_process_open_fds{k8s_app="cilium", pod=~"cilium.*"})
    ray_gram @@@ sum(ray_node_gram_used{ray_io_cluster=~"^{{ exp_global_model_name }}.*"}) / on() (sum(ray_node_gram_available{ray_io_cluster=~"^{{ exp_global_model_name }}.*"}) + sum(ray_node_gram_used{ray_io_cluster=~"^{{ exp_global_model_name }}.*"})) * 100
    ray_mem_util @@@ sum(ray_node_mem_used{ray_io_cluster=~"^{{ exp_global_model_name }}.*"}) / on() (sum(ray_node_mem_total{ray_io_cluster=~"^{{ exp_global_model_name }}.*"})) * 100
    ray_cpu_util @@@ sum(ray_node_cpu_utilization{ray_io_cluster=~"^{{ exp_global_model_name }}.*"})
    ray_network @@@ sum(ray_node_network_receive_speed{ray_io_cluster=~"^{{ exp_global_model_name }}.*"})
    rayserve_deployment_num_requests @@@ sum(rate(ray_serve_deployment_request_counter_total{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m]))
    rayserve_deployment_num_requests_ongoing @@@ sum(ray_serve_replica_processing_queries{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"})
    rayserve_deployment_num_requests_queued @@@ sum(ray_serve_deployment_queued_queries{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"})
    rayserve_deployment_num_errors @@@ sum(rate(ray_serve_deployment_error_counter_total{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m]))
    rayserve_deployment_p99_latency @@@ histogram_quantile(0.99, sum(rate(ray_serve_deployment_processing_latency_ms_bucket{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m])) by (le))
    rayserve_num_requests_http @@@ sum(rate(ray_serve_num_http_requests_total{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m]))
    rayserve_num_requests_http_ongoing @@@ sum(ray_serve_num_ongoing_http_requests{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"})
    rayserve_num_requests_http_error @@@ sum(rate(ray_serve_num_http_error_requests_total{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m]))
    rayserve_num_requests_router @@@ sum(rate(ray_serve_num_router_requests_total{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m]))
    rayserve_num_requests_handlers @@@ sum(rate(ray_serve_handle_request_counter_total{deployment="{{ ray_service_deployment_name }}",ray_io_cluster=~"^{{ exp_global_model_name }}.*"}[1m]))
    rayvllm_num_requests_success @@@ sum(rate(ray_vllm:request_success_total{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m]))
    rayvllm_num_requests_ongoing @@@ sum(ray_vllm:num_requests_running{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"})
    rayvllm_num_requests_waiting @@@ sum(ray_vllm:num_requests_waiting{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"})
    rayvllm_num_requests_swapped @@@ sum(ray_vllm:num_requests_swapped{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"})
    rayvllm_num_preemptions @@@ sum(rate(ray_vllm:num_preemptions_total{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m]))
    rayvllm_prompt_tokens @@@ sum(rate(ray_vllm:prompt_tokens_total{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m]))
    rayvllm_generation_tokens @@@ sum(rate(ray_vllm:generation_tokens_total{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m]))
    rayvllm_p99_time_to_first_token @@@ histogram_quantile(0.99, sum(rate(ray_vllm:time_to_first_token_seconds_bucket{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m])) by (le))
    rayvllm_p99_time_per_output_token @@@ histogram_quantile(0.99, sum(rate(ray_vllm:time_per_output_token_seconds_bucket{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m])) by (le))
    rayvllm_p99_e2e_request_latency @@@ histogram_quantile(0.99, sum(rate(ray_vllm:e2e_request_latency_seconds_bucket{ray_io_cluster=~"^{{ exp_global_model_name }}.*", model_name="{{ exp_global_model_name }}"}[1m])) by (le))
{% if dcgm_pci_bus_ids_concat is defined %}
    dcgm_gpu_power_usage @@@ sum(DCGM_FI_DEV_POWER_USAGE{pci_bus_id=~"{{ dcgm_pci_bus_ids_concat }}"})
    dcgm_gpu_utilization @@@ avg(DCGM_FI_DEV_GPU_UTIL{pci_bus_id=~"{{ dcgm_pci_bus_ids_concat }}"})
    dcgm_gpu_temperature @@@ avg(DCGM_FI_DEV_GPU_TEMP{pci_bus_id=~"{{ dcgm_pci_bus_ids_concat }}"})
{% endif %}
  export_metrics.py: |
    {{ export_metrics_python_script_content | indent(4) }}
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-csv-pvc
  namespace: {{ prometheus_csv_namespace }}
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: prometheus-csv-pod
  namespace: {{ prometheus_csv_namespace }}
spec:
  restartPolicy: Never
  containers:
    - name: prometheus-csv-container
      image: {{ prometheus_csv_image }}
      imagePullPolicy: Always
      volumeMounts:
        - name: prometheus-csv-storage
          mountPath: /app/csv
        - name: prometheus-csv-config
          mountPath: /app/config
      args:
        - uv
        - run
        - --with
        - requests
        - --with
        - python-dateutil
        - /app/config/export_metrics.py
      env:
        - name: EXPORT_METRICS_PYTHON_SCRIPT_BASE_URL
          value: http://kube-prometheus-stack-prometheus.observability.svc:9090
        - name: EXPORT_METRICS_PYTHON_SCRIPT_START_TIME_STR
          value: {{ fetch_start_time }}
        - name: EXPORT_METRICS_PYTHON_SCRIPT_END_TIME_STR
          value: {{ fetch_end_time }}
        - name: EXPORT_METRICS_PYTHON_SCRIPT_RESULT_FILE_NAME
          value: {{ fetch_result_file_name }}
  volumes:
    - name: prometheus-csv-storage
      persistentVolumeClaim:
        claimName: prometheus-csv-pvc
    - name: prometheus-csv-config
      configMap:
        name: prometheus-csv-configmap